---
title: "Inferring Microbial Networks in Different Soil Conditions"
author: "Dexter Chen"
date: "10/10/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Preprocessing

The raw dataset soil_**sample_gr2.rds** consists of three subsets: **otu_table**, **tax_table** and **sam_data**.

    - Firstly, remove taxa not seen more than 3 times in at least 20% of the samples. Due to the missing taxonomy information, only keep until the family level.

    - Split by soil conditions and filter 0 counts taxas

    - Keep only shared taxas in 2 conditions

```{r Preprocessing, echo=FALSE, message=FALSE, warning=FALSE}
library(phyloseq)
library(SPRING)
library(SpiecEasi)
library(JGL)
library(EstimateGroupNetwork)
library(SpiecEasi)
library(igraph)
library(caret)     # For confusionMatrix function
library(pROC)      # For ROC and AUC calculation
library(MLmetrics) # For F1 Score, MCC
library(ggraph)
library(igraph)
library(tidyverse)
library(tibble)
library(RColorBrewer)
data_soil_raw <- readRDS("data\\soil_sample_gr2.rds")
data_soil = filter_taxa(data_soil_raw, function(x) sum(x > 3) > (0.2*length(x)), TRUE)
otu_Ab <- t(otu_table(data_soil))
otu_tax <- tax_table(data_soil)[,1:5]
soil_info <- sample_data(data_soil)[, "Soil_Type"]
otu_Ab_naural <- otu_Ab[soil_info == "Forest",
                        colSums(otu_Ab[soil_info == "Forest",]) != 0]
otu_Ab_potting <- otu_Ab[soil_info == "Potting",
                        colSums(otu_Ab[soil_info == "Potting",]) != 0]
shared_taxa <- intersect(colnames(otu_Ab_naural), colnames(otu_Ab_potting))
otu_Ab_naural <- otu_Ab_naural[, shared_taxa]
otu_Ab_potting <- otu_Ab_potting[, shared_taxa]
head(otu_Ab_naural,n = c(5,5))
head(otu_Ab_potting,n = c(5,5))
```

## Synthesize simulated networks

### Normalization and scaling
Now, normalize and scale the aboundance data by default. Firstly,  calculate the sum of each row (representing the sequencing depth for each sample) and finds the minimum depth across all samples. Then, normalize each row to sum to 1 and multiply the normalized values by the minimum depth. Finally, round the scaled values to integers. This method aims to adjust the data to a common scale while preserving the relative abundance of features within each sample.

### mClr and correlation matrix
The second part of the function performs modifed centre logratio using **SPRING** and estimate the correlation matrix using **mixedCCA**.

Finally, apply joint graphical lasso and generate the true nerwork using the **EstimateGroupNetwork**

```{r Synthesize, echo = FALSE, message=FALSE, warning=FALSE}
preprocess_and_estimate_network <- function(data_list, labels = NULL,  nlambda1 = 10, nlambda2 = 10){
  norm_to_total <- function(x) x / sum(x)
  common_scaling <- function(data) {
    depths <- rowSums(data)
    data_normalized <- t(apply(data, 1, norm_to_total))
    common_depth <- min(depths)
    data_common_scaled <- round(data_normalized * common_depth) 
    return(data_common_scaled)
  }
  processed_data_list <- lapply(data_list, function(data) {
    scaled_data <- common_scaling(data)
    mclr_data <- mclr(scaled_data) # Using SPRING's mclr
    Kcor <- mixedCCA::estimateR(mclr_data, type = "trunc", method = "approx", tol = 1e-6, verbose = FALSE)$R
    return(Kcor)
  })
  n_samples <- sapply(data_list, nrow)
  Res <- EstimateGroupNetwork(
    processed_data_list, 
    inputType = "list.of.covariance.matrices",
    n = n_samples,
    labels = labels, # Pass labels directly 
    nlambda1 = nlambda1, 
    nlambda2 = nlambda2, 
    truncate = 1e-10, 
    criterion = 'aic'
  )

  return(Res)
}
data_list <- list(naural = otu_Ab_naural, potting = otu_Ab_potting)
network_results <- preprocess_and_estimate_network(data_list, labels = shared_taxa)
network_naural <- network_results$naural
network_potting <- network_results$potting
head(network_naural,n = c(5,5))
head(network_potting,n = c(5,5))
```

## Visualize on the network

### Edge weights distribution
Now, plot the distribution of edge weights, which represents the abs correlation between two OTUs.
```{r Edge, echo = FALSE, message=FALSE, warning=FALSE}
cor_values_naural <- as.vector(network_naural)
cor_values_potting <- as.vector(network_potting)
cor_df <- data.frame(
  correlation = c(cor_values_naural, cor_values_potting),
  group = factor(rep(c("Natural", "Potting"), each = length(cor_values_naural)))
)
hist_plot <- ggplot(cor_df, aes(x = correlation, fill = group)) +
  geom_histogram(position = "dodge", bins = 30, alpha = 0.7) +
  scale_fill_manual(values = c("Natural" = "blue", "Potting" = "red")) +
  theme_minimal() +
  labs(title = "Distribution of Correlation Values",
       x = "Correlation",
       y = "Frequency",
       fill = "Soil Type")
print(hist_plot)
```
### Plot network
Visualize the hierarchical edge network seperately.
```{r Network, echo = FALSE, message=FALSE, warning=FALSE}
otu_tax_df <- otu_tax %>%
as.data.frame() %>%
tibble::rownames_to_column("OTU") %>%
dplyr::select(OTU, everything())

pairs <- list(
c("Kingdom", "Phylum"),
c("Phylum", "Class"),
c("Class", "Order"),
c("Order", "Family"),
c("Family", "OTU"))
create_edges <- function(pair, data)
{
    from <- data[[pair[1]]]
    to <- data[[pair[2]]]
    data.frame(from = from, to = to)
}
edges <- unique(do.call(rbind, lapply(pairs, create_edges, data = otu_tax_df[otu_tax_df$OTU %in% shared_taxa, ])))
lower_tri <- lower.tri(network_naural, diag = FALSE)
non_zero <- which(lower_tri & network_naural != 0, arr.ind = TRUE)
connect <- data.frame(
from = rownames(network_naural)[non_zero[, 1]],
to = colnames(network_naural)[non_zero[, 2]],
score = network_naural[non_zero])
vertices  <-  data.frame(
name = unique(c(as.character(edges$from), as.character(edges$to))) , 
value = runif(length(unique(c(as.character(edges$from), as.character(edges$to))))))
vertices$group  <-  edges$from[ match( vertices$name, edges$to ) ]
vertices$id <- NA
myleaves <- which(is.na(match(vertices$name, edges$from)))
vertices$value[myleaves] <- colSums(network_naural) / sum(network_naural)
nleaves <- length(myleaves)
vertices$id[myleaves] <- seq(1:nleaves)
vertices$angle <- 90 - 360 * vertices$id / nleaves
vertices$angle <- ifelse(vertices$angle < -90, vertices$angle+180, vertices$angle)
vertices$hjust <- ifelse( vertices$angle < -90, 1, 0)
mygraph <- igraph::graph_from_data_frame( edges, vertices=vertices )
from  <-  match( connect$from, vertices$name)
to  <-  match( connect$to, vertices$name)
p <- ggraph(mygraph, layout = 'dendrogram', circular = TRUE) + 
geom_conn_bundle(data = get_con(from = from, to = to), alpha=0.2, width=0.1, aes(colour = after_stat(index))) +
scale_edge_colour_gradient(low = "red", high = "blue") +
geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = angle, hjust=hjust, colour=group), size=2, alpha=1) +
geom_node_point(aes(filter = leaf, x = x*1.07, y=y*1.07, colour=group, size=value, alpha=0.2)) +
scale_colour_manual(values= rep(brewer.pal(14,"Paired") , 30)) +
scale_size_continuous(range = c(0.1,10) ) +
theme_void() +
theme(
    legend.position="none",
    plot.margin=unit(c(0,0,0,0),"cm"),
) +
expand_limits(x = c(-1.3, 1.3), y = c(-1.3, 1.3))
print(p)

```
## Evaluate synthesized dataset
Now, synthesize 10 dataset based on the origin/true aboundance data.

```{r Evaluate, echo = FALSE, message=FALSE, warning=FALSE}
true_adj_naural <- (network_naural !=0)*1
true_adj_potting <- (network_potting !=0)*1
set.seed(10010)
synthesize_scaled_data <- function(dat, net)
  {
    graph <- (net != 0)*1     # SpiecEasi::make_graph('cluster', dat$n_OTUs, dat$n_edge)
    attr(graph, "class") <- "graph"
    Prec <- SpiecEasi::graph2prec(graph)
    Cor <- cov2cor(SpiecEasi::prec2cov(Prec))
    X <- SpiecEasi::synth_comm_from_counts(dat, mar = 2, distr = 'zinegbin', Sigma = Cor, n = nrow(dat))
    return(X)
  }
Sim_list <- list()
for (i in 1:10)
  {
    Sim_list[[i]] <- list(
      naural = synthesize_scaled_data(otu_Ab_naural, network_naural),
      potting = synthesize_scaled_data(otu_Ab_potting, network_potting)
    )
  }
Res_sim <- list()
for (i in 1:10)
  {
    Res_sim[[i]] <- preprocess_and_estimate_network(Sim_list[[i]], labels = shared_taxa)
  }
Sim_adj <- list()
for (i in 1:10)
  {
    Sim_adj[[i]] <- list(
      naural = (Res_sim[[i]]$naural !=0)*1,
      potting = (Res_sim[[i]]$potting !=0)*1
    )
  }
calculate_mcc <- function(tp, tn, fp, fn)
  {
    numerator <- (tp * tn) - (fp * fn)
    denominator <- sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
  
    # If the denominator is 0, return 0 to avoid NaN errors
    if (denominator == 0) {
      return(0)
    } else {
      return(numerator / denominator)
    }
  }
calculate_metrics <- function(true_adj, sim_adj)
  {
    # Flatten the matrices into vectors (upper triangular part, excluding diagonal)
    true_edges <- as.vector(true_adj[upper.tri(true_adj)])
    sim_edges <- as.vector(sim_adj[upper.tri(sim_adj)])
  
    # Confusion matrix
    cm <- confusionMatrix(as.factor(sim_edges), as.factor(true_edges), positive = "1")
    tn <- as.numeric(cm$table[1,1]) #true negatives
    fp <- as.numeric(cm$table[1,2]) #false positives
    fn <- as.numeric(cm$table[2,1]) #false negatives
    tp <- as.numeric(cm$table[2,2]) #true positives
  
    # Calculate TPR, FPR, Precision, Recall
    tpr <- tp / (tp + fn)  # Sensitivity / Recall
    fpr <- fp / (fp + tn)  # 1 - Specificity
    precision <- tp / (tp + fp)
    recall <- tpr
  
    # Calculate ROC and AUC
    roc_obj <- roc(true_edges, sim_edges)
    auc <- as.numeric(auc(roc_obj)) # plot here
  
    # F1 Score
    f1 <- F1_Score(sim_edges, true_edges)
  
    # MCC (Matthews correlation coefficient)
    mcc <- calculate_mcc(tp, tn, fp, fn)
  
    # Return metrics as a list
    return(list(TPR = tpr, FPR = fpr, Precision = precision, Recall = recall,
                F1 = f1, AUC = auc, MCC = mcc))
  }
confusion_results <- lapply(1:10, function(i)
    {
    # Calculate metrics for both natural and potting
    natural_metrics <- calculate_metrics(true_adj_naural, Sim_adj[[i]]$naural)
    potting_metrics <- calculate_metrics(true_adj_potting, Sim_adj[[i]]$potting)
    # Return both results as a named list
    return(list(natural = natural_metrics, potting = potting_metrics))
    } )
results_df <- do.call(rbind, lapply(confusion_results, as.data.frame))
head(results_df,n = c(5,5))
```

## Plot barplots to see the simulated matrices
```{r Plot,  echo = FALSE,message=FALSE, warning=FALSE}
results_df_long <- results_df %>%
  dplyr::select(starts_with("natural.") | starts_with("potting.")) %>%
  tidyr::pivot_longer(cols = everything(), 
               names_to = c("group", "metric"), 
               names_sep = "\\.",
               values_to = "value") %>%
  dplyr::mutate(matrix_id = rep(1:10, each = 14)) # Add matrix ID

# Create separate plots for each metric
for (metric_name in unique(results_df_long$metric)) {
    plot_data <- results_df_long %>%
        dplyr::filter(metric == metric_name)
    
    p <- ggplot(plot_data, aes(x = matrix_id, y = value, fill = group)) +
        geom_bar(stat = "identity", position = "dodge") +
        labs(title = paste(metric_name, "for Simulated Networks"),
            x = "Matrix ID",
            y = metric_name) +
        theme_bw()
    print(p)
  #ggsave(paste0(metric_name, "_plot.png"), p)
}
```
